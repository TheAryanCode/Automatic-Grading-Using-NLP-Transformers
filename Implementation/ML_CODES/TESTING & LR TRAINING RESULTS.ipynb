{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LINEAR REGRESSION TRAINING RESULTS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding_0</th>\n",
       "      <th>embedding_1</th>\n",
       "      <th>embedding_2</th>\n",
       "      <th>embedding_3</th>\n",
       "      <th>embedding_4</th>\n",
       "      <th>embedding_5</th>\n",
       "      <th>embedding_6</th>\n",
       "      <th>embedding_7</th>\n",
       "      <th>embedding_8</th>\n",
       "      <th>embedding_9</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_375</th>\n",
       "      <th>embedding_376</th>\n",
       "      <th>embedding_377</th>\n",
       "      <th>embedding_378</th>\n",
       "      <th>embedding_379</th>\n",
       "      <th>embedding_380</th>\n",
       "      <th>embedding_381</th>\n",
       "      <th>embedding_382</th>\n",
       "      <th>embedding_383</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.036731</td>\n",
       "      <td>-0.256311</td>\n",
       "      <td>0.839563</td>\n",
       "      <td>0.082782</td>\n",
       "      <td>-0.107343</td>\n",
       "      <td>-0.260510</td>\n",
       "      <td>0.153342</td>\n",
       "      <td>-0.442883</td>\n",
       "      <td>-0.200667</td>\n",
       "      <td>0.136390</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.254796</td>\n",
       "      <td>-0.281328</td>\n",
       "      <td>0.007009</td>\n",
       "      <td>-0.294743</td>\n",
       "      <td>0.304695</td>\n",
       "      <td>0.018429</td>\n",
       "      <td>-0.409374</td>\n",
       "      <td>0.039161</td>\n",
       "      <td>-0.163540</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.301357</td>\n",
       "      <td>0.222360</td>\n",
       "      <td>0.552619</td>\n",
       "      <td>-0.363341</td>\n",
       "      <td>-0.269042</td>\n",
       "      <td>-0.081171</td>\n",
       "      <td>0.439332</td>\n",
       "      <td>-0.398349</td>\n",
       "      <td>0.077303</td>\n",
       "      <td>0.175214</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.267180</td>\n",
       "      <td>-0.211732</td>\n",
       "      <td>-0.088311</td>\n",
       "      <td>-0.291997</td>\n",
       "      <td>0.674493</td>\n",
       "      <td>0.212739</td>\n",
       "      <td>-0.261213</td>\n",
       "      <td>0.077797</td>\n",
       "      <td>-0.201160</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.178587</td>\n",
       "      <td>-0.065338</td>\n",
       "      <td>0.463976</td>\n",
       "      <td>-0.077023</td>\n",
       "      <td>0.028036</td>\n",
       "      <td>-0.498548</td>\n",
       "      <td>0.268914</td>\n",
       "      <td>-0.234962</td>\n",
       "      <td>0.105622</td>\n",
       "      <td>0.296332</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.152507</td>\n",
       "      <td>-0.407300</td>\n",
       "      <td>0.110268</td>\n",
       "      <td>-0.515028</td>\n",
       "      <td>0.490852</td>\n",
       "      <td>-0.186274</td>\n",
       "      <td>-0.382561</td>\n",
       "      <td>-0.156790</td>\n",
       "      <td>-0.018635</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.275285</td>\n",
       "      <td>0.002881</td>\n",
       "      <td>0.494406</td>\n",
       "      <td>-0.250185</td>\n",
       "      <td>0.020868</td>\n",
       "      <td>0.068024</td>\n",
       "      <td>0.262423</td>\n",
       "      <td>-0.287438</td>\n",
       "      <td>0.017845</td>\n",
       "      <td>0.267704</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.345155</td>\n",
       "      <td>-0.116877</td>\n",
       "      <td>-0.113963</td>\n",
       "      <td>-0.443824</td>\n",
       "      <td>0.442446</td>\n",
       "      <td>-0.079149</td>\n",
       "      <td>-0.238616</td>\n",
       "      <td>0.117454</td>\n",
       "      <td>0.029507</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.407440</td>\n",
       "      <td>0.035231</td>\n",
       "      <td>0.688848</td>\n",
       "      <td>-0.528462</td>\n",
       "      <td>-0.113518</td>\n",
       "      <td>-0.015912</td>\n",
       "      <td>0.320460</td>\n",
       "      <td>-0.438466</td>\n",
       "      <td>-0.030067</td>\n",
       "      <td>0.050064</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.245750</td>\n",
       "      <td>-0.218754</td>\n",
       "      <td>-0.163055</td>\n",
       "      <td>-0.402943</td>\n",
       "      <td>0.562030</td>\n",
       "      <td>-0.002069</td>\n",
       "      <td>-0.301637</td>\n",
       "      <td>0.130856</td>\n",
       "      <td>0.127899</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 385 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   embedding_0  embedding_1  embedding_2  embedding_3  embedding_4  \\\n",
       "0    -0.036731    -0.256311     0.839563     0.082782    -0.107343   \n",
       "1     0.301357     0.222360     0.552619    -0.363341    -0.269042   \n",
       "2     0.178587    -0.065338     0.463976    -0.077023     0.028036   \n",
       "3     0.275285     0.002881     0.494406    -0.250185     0.020868   \n",
       "4     0.407440     0.035231     0.688848    -0.528462    -0.113518   \n",
       "\n",
       "   embedding_5  embedding_6  embedding_7  embedding_8  embedding_9  ...  \\\n",
       "0    -0.260510     0.153342    -0.442883    -0.200667     0.136390  ...   \n",
       "1    -0.081171     0.439332    -0.398349     0.077303     0.175214  ...   \n",
       "2    -0.498548     0.268914    -0.234962     0.105622     0.296332  ...   \n",
       "3     0.068024     0.262423    -0.287438     0.017845     0.267704  ...   \n",
       "4    -0.015912     0.320460    -0.438466    -0.030067     0.050064  ...   \n",
       "\n",
       "   embedding_375  embedding_376  embedding_377  embedding_378  embedding_379  \\\n",
       "0      -0.254796      -0.281328       0.007009      -0.294743       0.304695   \n",
       "1      -0.267180      -0.211732      -0.088311      -0.291997       0.674493   \n",
       "2      -0.152507      -0.407300       0.110268      -0.515028       0.490852   \n",
       "3      -0.345155      -0.116877      -0.113963      -0.443824       0.442446   \n",
       "4      -0.245750      -0.218754      -0.163055      -0.402943       0.562030   \n",
       "\n",
       "   embedding_380  embedding_381  embedding_382  embedding_383  output  \n",
       "0       0.018429      -0.409374       0.039161      -0.163540     0.0  \n",
       "1       0.212739      -0.261213       0.077797      -0.201160     0.0  \n",
       "2      -0.186274      -0.382561      -0.156790      -0.018635     0.0  \n",
       "3      -0.079149      -0.238616       0.117454       0.029507     0.0  \n",
       "4      -0.002069      -0.301637       0.130856       0.127899     0.0  \n",
       "\n",
       "[5 rows x 385 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_excel(\"C:/Users/aryan/.cursor-tutor-2/output_file.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop('output',axis=1)\n",
    "y=df['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "output\n",
       "3.0    272\n",
       "4.0    262\n",
       "2.0    186\n",
       "5.0    131\n",
       "2.5     64\n",
       "1.0     62\n",
       "4.5     52\n",
       "3.5     44\n",
       "0.5     22\n",
       "1.5     19\n",
       "0.0     13\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def custom_round(value):\n",
    "    integer_part = int(value)\n",
    "    decimal_part = value - integer_part\n",
    "    if decimal_part == 0.5:\n",
    "        return value\n",
    "    else:\n",
    "        return round(value)\n",
    "\n",
    "# Apply the custom rounding function to the 'value' column\n",
    "df['output'] = df['output'].apply(custom_round)\n",
    "df['output'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV,train_test_split,RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "std=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_x_train=std.fit_transform(x_train)\n",
    "scaled_x_test=std.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "icm=IncrementalPCA(n_components=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1=icm.fit_transform(scaled_x_train)\n",
    "x_test1=icm.transform(scaled_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.49134713, -1.77221973, -2.36674397, ...,  0.20104948,\n",
       "        -0.20094647, -0.1825587 ],\n",
       "       [ 9.05994623,  8.61613999,  9.17582548, ..., -0.29370702,\n",
       "         0.04292501, -0.14662804],\n",
       "       [ 4.29140623,  0.01390929,  6.88785863, ..., -0.0108384 ,\n",
       "        -0.10388302,  0.01062526],\n",
       "       ...,\n",
       "       [ 1.47099486,  5.08214169, -0.22973492, ..., -0.25035433,\n",
       "        -0.10582254, -0.74579533],\n",
       "       [ 8.87480298, -2.17335053, -3.17732627, ..., -0.03451363,\n",
       "        -0.11742936, -0.18164713],\n",
       "       [-0.15241678,  3.7858978 , -0.72092348, ..., -0.10459839,\n",
       "         0.02967007, -0.02776387]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas=list(np.arange(0,3,0.01))\n",
    "param_grid={\n",
    "    'alpha': alphas\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet,RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "els=ElasticNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtk=GridSearchCV(els,param_grid=param_grid,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aryan\\radioconda\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\aryan\\radioconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\aryan\\radioconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.696e+02, tolerance: 1.077e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\aryan\\radioconda\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\aryan\\radioconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\aryan\\radioconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.634e+02, tolerance: 1.094e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\aryan\\radioconda\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\aryan\\radioconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\aryan\\radioconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.651e+02, tolerance: 1.104e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\aryan\\radioconda\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\aryan\\radioconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\aryan\\radioconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.657e+02, tolerance: 1.056e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\aryan\\radioconda\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\aryan\\radioconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\aryan\\radioconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.677e+02, tolerance: 1.116e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\aryan\\radioconda\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\aryan\\radioconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\aryan\\radioconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.714e+02, tolerance: 1.107e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\aryan\\radioconda\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\aryan\\radioconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\aryan\\radioconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.623e+02, tolerance: 1.078e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\aryan\\radioconda\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\aryan\\radioconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\aryan\\radioconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.709e+02, tolerance: 1.096e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\aryan\\radioconda\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\aryan\\radioconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\aryan\\radioconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.670e+02, tolerance: 1.076e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\aryan\\radioconda\\Lib\\site-packages\\sklearn\\base.py:1473: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\aryan\\radioconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\aryan\\radioconda\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.685e+02, tolerance: 1.080e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=ElasticNet(),\n",
       "             param_grid={&#x27;alpha&#x27;: [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06,\n",
       "                                   0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13,\n",
       "                                   0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2,\n",
       "                                   0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27,\n",
       "                                   0.28, 0.29, ...]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=10, estimator=ElasticNet(),\n",
       "             param_grid={&#x27;alpha&#x27;: [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06,\n",
       "                                   0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13,\n",
       "                                   0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2,\n",
       "                                   0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27,\n",
       "                                   0.28, 0.29, ...]})</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: ElasticNet</label><div class=\"sk-toggleable__content fitted\"><pre>ElasticNet(alpha=0.02)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;ElasticNet<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.ElasticNet.html\">?<span>Documentation for ElasticNet</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ElasticNet(alpha=0.02)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=ElasticNet(),\n",
       "             param_grid={'alpha': [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06,\n",
       "                                   0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13,\n",
       "                                   0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2,\n",
       "                                   0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27,\n",
       "                                   0.28, 0.29, ...]})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtk.fit(x_train1,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ElasticNet(alpha=0.02)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;ElasticNet<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.ElasticNet.html\">?<span>Documentation for ElasticNet</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>ElasticNet(alpha=0.02)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "ElasticNet(alpha=0.02)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtk.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "vvr=ElasticNet(alpha=0.011,l1_ratio=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ElasticNet(alpha=0.011, l1_ratio=0.9)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;ElasticNet<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.ElasticNet.html\">?<span>Documentation for ElasticNet</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>ElasticNet(alpha=0.011, l1_ratio=0.9)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "ElasticNet(alpha=0.011, l1_ratio=0.9)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vvr.fit(x_train1,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr=vvr.predict(x_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4751967465077629"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=gtk.predict(x_test1)\n",
    "from sklearn.metrics import mean_squared_error,r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47460042546840164"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9321938601666884"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9655018695821818"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test,test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=ElasticNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poram_grid={\n",
    "    'alpha':list(np.arange(0,3,0.01)), \n",
    "    'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9,1]  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.135e+02, tolerance: 1.154e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.111e+02, tolerance: 1.141e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.092e+02, tolerance: 1.160e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.129e+02, tolerance: 1.161e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.112e+02, tolerance: 1.162e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.129e+02, tolerance: 1.153e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.131e+02, tolerance: 1.143e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.098e+02, tolerance: 1.137e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.161e+02, tolerance: 1.165e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.110e+02, tolerance: 1.174e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.193e+02, tolerance: 1.171e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.110e+02, tolerance: 1.156e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.082e+02, tolerance: 1.134e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.162e+02, tolerance: 1.164e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.195e+02, tolerance: 1.166e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.155e+02, tolerance: 1.146e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.106e+02, tolerance: 1.142e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.129e+02, tolerance: 1.160e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.133e+02, tolerance: 1.139e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.160e+02, tolerance: 1.162e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.135e+02, tolerance: 1.154e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.111e+02, tolerance: 1.141e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.092e+02, tolerance: 1.160e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.129e+02, tolerance: 1.161e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.112e+02, tolerance: 1.162e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.129e+02, tolerance: 1.153e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.131e+02, tolerance: 1.143e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.098e+02, tolerance: 1.137e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.161e+02, tolerance: 1.165e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.110e+02, tolerance: 1.174e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.193e+02, tolerance: 1.171e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.110e+02, tolerance: 1.156e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.082e+02, tolerance: 1.134e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.162e+02, tolerance: 1.164e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.195e+02, tolerance: 1.166e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.155e+02, tolerance: 1.146e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.106e+02, tolerance: 1.142e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.129e+02, tolerance: 1.160e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.133e+02, tolerance: 1.139e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.160e+02, tolerance: 1.162e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.135e+02, tolerance: 1.154e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.111e+02, tolerance: 1.141e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.092e+02, tolerance: 1.160e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.129e+02, tolerance: 1.161e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.112e+02, tolerance: 1.162e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.129e+02, tolerance: 1.153e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.131e+02, tolerance: 1.143e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.098e+02, tolerance: 1.137e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.161e+02, tolerance: 1.165e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.110e+02, tolerance: 1.174e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.193e+02, tolerance: 1.171e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.110e+02, tolerance: 1.156e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.082e+02, tolerance: 1.134e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.162e+02, tolerance: 1.164e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.195e+02, tolerance: 1.166e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.155e+02, tolerance: 1.146e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.106e+02, tolerance: 1.142e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.129e+02, tolerance: 1.160e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.133e+02, tolerance: 1.139e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.160e+02, tolerance: 1.162e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.135e+02, tolerance: 1.154e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.111e+02, tolerance: 1.141e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.092e+02, tolerance: 1.160e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.129e+02, tolerance: 1.161e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.112e+02, tolerance: 1.162e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.129e+02, tolerance: 1.153e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.131e+02, tolerance: 1.143e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.098e+02, tolerance: 1.137e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.161e+02, tolerance: 1.165e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.110e+02, tolerance: 1.174e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.193e+02, tolerance: 1.171e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.110e+02, tolerance: 1.156e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.082e+02, tolerance: 1.134e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.162e+02, tolerance: 1.164e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.195e+02, tolerance: 1.166e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.155e+02, tolerance: 1.146e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.106e+02, tolerance: 1.142e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.129e+02, tolerance: 1.160e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.133e+02, tolerance: 1.139e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.160e+02, tolerance: 1.162e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.135e+02, tolerance: 1.154e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.111e+02, tolerance: 1.141e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.092e+02, tolerance: 1.160e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.129e+02, tolerance: 1.161e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.112e+02, tolerance: 1.162e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.129e+02, tolerance: 1.153e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.131e+02, tolerance: 1.143e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.098e+02, tolerance: 1.137e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.161e+02, tolerance: 1.165e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.110e+02, tolerance: 1.174e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.193e+02, tolerance: 1.171e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.110e+02, tolerance: 1.156e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.082e+02, tolerance: 1.134e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.162e+02, tolerance: 1.164e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.195e+02, tolerance: 1.166e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.155e+02, tolerance: 1.146e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.106e+02, tolerance: 1.142e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.129e+02, tolerance: 1.160e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.133e+02, tolerance: 1.139e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\naman\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.160e+02, tolerance: 1.162e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-20 {color: black;}#sk-container-id-20 pre{padding: 0;}#sk-container-id-20 div.sk-toggleable {background-color: white;}#sk-container-id-20 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-20 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-20 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-20 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-20 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-20 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-20 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-20 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-20 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-20 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-20 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-20 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-20 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-20 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-20 div.sk-item {position: relative;z-index: 1;}#sk-container-id-20 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-20 div.sk-item::before, #sk-container-id-20 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-20 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-20 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-20 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-20 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-20 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-20 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-20 div.sk-label-container {text-align: center;}#sk-container-id-20 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-20 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-20\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=20, estimator=ElasticNet(), n_iter=1000,\n",
       "                   param_distributions={&#x27;alpha&#x27;: [0.0, 0.01, 0.02, 0.03, 0.04,\n",
       "                                                  0.05, 0.06, 0.07, 0.08, 0.09,\n",
       "                                                  0.1, 0.11, 0.12, 0.13, 0.14,\n",
       "                                                  0.15, 0.16, 0.17, 0.18, 0.19,\n",
       "                                                  0.2, 0.21, 0.22, 0.23, 0.24,\n",
       "                                                  0.25, 0.26, 0.27, 0.28, 0.29, ...],\n",
       "                                        &#x27;l1_ratio&#x27;: [0.1, 0.3, 0.5, 0.7, 0.9]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-42\" type=\"checkbox\" ><label for=\"sk-estimator-id-42\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=20, estimator=ElasticNet(), n_iter=1000,\n",
       "                   param_distributions={&#x27;alpha&#x27;: [0.0, 0.01, 0.02, 0.03, 0.04,\n",
       "                                                  0.05, 0.06, 0.07, 0.08, 0.09,\n",
       "                                                  0.1, 0.11, 0.12, 0.13, 0.14,\n",
       "                                                  0.15, 0.16, 0.17, 0.18, 0.19,\n",
       "                                                  0.2, 0.21, 0.22, 0.23, 0.24,\n",
       "                                                  0.25, 0.26, 0.27, 0.28, 0.29, ...],\n",
       "                                        &#x27;l1_ratio&#x27;: [0.1, 0.3, 0.5, 0.7, 0.9]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-43\" type=\"checkbox\" ><label for=\"sk-estimator-id-43\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-44\" type=\"checkbox\" ><label for=\"sk-estimator-id-44\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=20, estimator=ElasticNet(), n_iter=1000,\n",
       "                   param_distributions={'alpha': [0.0, 0.01, 0.02, 0.03, 0.04,\n",
       "                                                  0.05, 0.06, 0.07, 0.08, 0.09,\n",
       "                                                  0.1, 0.11, 0.12, 0.13, 0.14,\n",
       "                                                  0.15, 0.16, 0.17, 0.18, 0.19,\n",
       "                                                  0.2, 0.21, 0.22, 0.23, 0.24,\n",
       "                                                  0.25, 0.26, 0.27, 0.28, 0.29, ...],\n",
       "                                        'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]})"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = RandomizedSearchCV(estimator=els, param_distributions=poram_grid, n_iter=1000, cv=20)\n",
    "rs.fit(x_train1,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m rs\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rs' is not defined"
     ]
    }
   ],
   "source": [
    "rs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1=rs.predict(x_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.75317977, 1.97540495, 3.33799827, 3.121654  , 2.10459377,\n",
       "       3.03711236, 4.24427931, 3.0376193 , 3.33305231, 2.82293229,\n",
       "       3.88502402, 2.71230692, 2.88042214, 2.94523902, 3.33968062,\n",
       "       1.52849737, 2.17903044, 2.51397035, 4.86813073, 2.10148972,\n",
       "       2.70312528, 2.65060318, 3.70893141, 3.9116313 , 2.18652253,\n",
       "       2.93490096, 3.51016475, 0.42980228, 2.94212199, 3.47844247,\n",
       "       2.05026553, 1.94423176, 3.56282277, 3.24756791, 3.56942169,\n",
       "       3.6535671 , 3.64581227, 3.34361035, 2.67658541, 3.18590064,\n",
       "       2.90852503, 2.88860075, 4.09923497, 2.51991552, 3.6919818 ,\n",
       "       3.83686912, 3.46298116, 3.89573592, 3.21541097, 3.27928547,\n",
       "       4.42583598, 3.0690402 , 1.01563891, 2.46260897, 3.86535629,\n",
       "       3.58016456, 2.67298832, 3.54697985, 3.45510706, 3.35130944,\n",
       "       2.55731341, 3.05982895, 3.25556025, 2.18988332, 3.18410151,\n",
       "       3.10356517, 1.90274731, 3.74600163, 3.58200352, 0.4613494 ,\n",
       "       2.91524962, 4.34083168, 2.30492368, 2.68071748, 2.46639356,\n",
       "       3.19817119, 3.31940132, 3.61080721, 3.63067892, 3.56433407,\n",
       "       1.90129865, 3.22771237, 2.71987222, 2.90802385, 2.97236326,\n",
       "       4.14247606, 4.09508255, 3.66642425, 3.56410554, 3.2140553 ,\n",
       "       3.27203871, 2.94149021, 3.10385691, 1.96738424, 2.74126901,\n",
       "       4.15559379, 3.5015336 , 2.00201655, 2.8952617 , 3.44403556,\n",
       "       4.17911277, 3.40140979, 3.16907963, 3.10666366, 3.59249388,\n",
       "       4.02846123, 3.66337308, 3.62156536, 3.32632256, 3.25324723,\n",
       "       3.43937472, 1.85647437, 3.97514306, 3.43130644, 4.15693452,\n",
       "       3.10127766, 3.16949431, 2.85256223, 3.91892515, 3.3737471 ,\n",
       "       1.83434383, 3.18431045, 3.56550832, 2.0003388 , 4.06357557,\n",
       "       1.26710872, 3.77345811, 3.14062225, 3.16907963, 2.70151593,\n",
       "       3.45589281, 3.19637611, 3.22419689, 2.51093917, 3.89047277,\n",
       "       3.1586022 , 2.03670098, 3.88685301, 2.25911561, 2.59345715,\n",
       "       3.12396061, 2.52238184, 2.27474815, 2.48323098, 2.07889047,\n",
       "       2.49726051, 2.95076441, 3.44007516, 3.25677643, 0.98311571,\n",
       "       2.9762612 , 3.47363569, 4.54445635, 3.92867982, 2.22959019,\n",
       "       1.7272214 , 2.0753431 , 3.18510365, 3.51063353, 2.64772103,\n",
       "       2.4412947 , 3.84444878, 3.02616893, 2.25911561, 4.16010814,\n",
       "       2.76416178, 1.75488725, 2.31748244, 3.59261724, 4.32202149,\n",
       "       3.45707127, 3.88591723, 2.70312528, 3.00803976, 3.94946463,\n",
       "       3.52486723, 2.81930356, 3.38907533, 2.31821355, 4.89372841,\n",
       "       1.93246477, 3.07449924, 3.09607095, 3.26980285, 3.81094794,\n",
       "       4.26605437, 3.75546561, 2.70312528, 3.17469033, 3.27362577,\n",
       "       4.18836985, 2.67385238, 3.22966496, 2.95280753, 2.59632214,\n",
       "       1.01565848, 3.01075435, 3.97912048, 3.97832896, 3.86949491,\n",
       "       3.48841761, 2.61846301, 4.63876629, 2.13464406, 3.52811484,\n",
       "       3.37097836, 3.58011983, 3.94032237, 3.69817755, 1.10386194,\n",
       "       3.71129068, 2.79529532, 3.58619787, 2.71634001, 2.90802385,\n",
       "       3.89650591, 3.77656371, 3.19055214, 3.09068595, 2.21845524,\n",
       "       2.71634001, 2.13541914, 2.6934602 , 2.13678074, 2.91604751,\n",
       "       4.2639023 ])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.935975060191339"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3570232212523836"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TESTING DATA RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   embedding_0  embedding_1  embedding_2  embedding_3  embedding_4  \\\n",
       " 0    -0.036731    -0.256311     0.839563     0.082782    -0.107343   \n",
       " 1     0.301357     0.222360     0.552619    -0.363341    -0.269042   \n",
       " 2     0.178587    -0.065338     0.463976    -0.077023     0.028036   \n",
       " 3     0.275285     0.002881     0.494406    -0.250185     0.020868   \n",
       " 4     0.407440     0.035231     0.688848    -0.528462    -0.113518   \n",
       " \n",
       "    embedding_5  embedding_6  embedding_7  embedding_8  embedding_9  ...  \\\n",
       " 0    -0.260510     0.153342    -0.442883    -0.200667     0.136390  ...   \n",
       " 1    -0.081171     0.439332    -0.398349     0.077303     0.175214  ...   \n",
       " 2    -0.498548     0.268914    -0.234962     0.105622     0.296332  ...   \n",
       " 3     0.068024     0.262423    -0.287438     0.017845     0.267704  ...   \n",
       " 4    -0.015912     0.320460    -0.438466    -0.030067     0.050064  ...   \n",
       " \n",
       "    embedding_375  embedding_376  embedding_377  embedding_378  embedding_379  \\\n",
       " 0      -0.254796      -0.281328       0.007009      -0.294743       0.304695   \n",
       " 1      -0.267180      -0.211732      -0.088311      -0.291997       0.674493   \n",
       " 2      -0.152507      -0.407300       0.110268      -0.515028       0.490852   \n",
       " 3      -0.345155      -0.116877      -0.113963      -0.443824       0.442446   \n",
       " 4      -0.245750      -0.218754      -0.163055      -0.402943       0.562030   \n",
       " \n",
       "    embedding_380  embedding_381  embedding_382  embedding_383  output  \n",
       " 0       0.018429      -0.409374       0.039161      -0.163540     0.0  \n",
       " 1       0.212739      -0.261213       0.077797      -0.201160     0.0  \n",
       " 2      -0.186274      -0.382561      -0.156790      -0.018635     0.0  \n",
       " 3      -0.079149      -0.238616       0.117454       0.029507     0.0  \n",
       " 4      -0.002069      -0.301637       0.130856       0.127899     0.0  \n",
       " \n",
       " [5 rows x 385 columns],\n",
       "    embedding_0  embedding_1  embedding_2  embedding_3  embedding_4  \\\n",
       " 0    -0.036732    -0.256312     0.839563     0.082782    -0.107343   \n",
       " 1    -0.030299    -0.098082     0.764166    -0.060261     0.086393   \n",
       " 2     0.269570     0.046050     0.740542    -0.105078    -0.317154   \n",
       " 3     0.027550    -0.004702     0.665193     0.035726    -0.075828   \n",
       " 4     0.422197    -0.203942     0.708060    -0.039512     0.185205   \n",
       " \n",
       "    embedding_5  embedding_6  embedding_7  embedding_8  embedding_9  ...  \\\n",
       " 0    -0.260510     0.153343    -0.442882    -0.200667     0.136391  ...   \n",
       " 1    -0.265188     0.117789    -0.345150    -0.139448     0.113236  ...   \n",
       " 2    -0.234961     0.389401    -0.394599    -0.187724     0.092695  ...   \n",
       " 3    -0.181230     0.137025    -0.200956    -0.220252     0.020297  ...   \n",
       " 4    -0.361203     0.224818     0.098835     0.182641     0.141594  ...   \n",
       " \n",
       "    embedding_375  embedding_376  embedding_377  embedding_378  embedding_379  \\\n",
       " 0      -0.254797      -0.281328       0.007009      -0.294743       0.304695   \n",
       " 1      -0.200132      -0.321002       0.050311      -0.485780       0.551534   \n",
       " 2      -0.337171      -0.283174       0.117318      -0.507154       0.650150   \n",
       " 3      -0.399034      -0.345991       0.050852      -0.463247       0.516602   \n",
       " 4      -0.158125      -0.557875       0.157921      -0.415116       0.552441   \n",
       " \n",
       "    embedding_380  embedding_381  embedding_382  embedding_383  output  \n",
       " 0       0.018428      -0.409373       0.039161      -0.163541    0.00  \n",
       " 1      -0.070342      -0.003264       0.087541      -0.003311    2.50  \n",
       " 2       0.036194      -0.060878       0.052914      -0.091993    4.50  \n",
       " 3       0.053787      -0.126225      -0.004659      -0.192148    5.00  \n",
       " 4      -0.208122      -0.385541       0.126919      -0.317933    1.25  \n",
       " \n",
       " [5 rows x 385 columns])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "training_data = pd.read_excel(\"C:/Users/aryan/.cursor-tutor-2/output_file.xlsx\")\n",
    "\n",
    "testing_data = pd.read_excel(\"C:/Users/aryan/Downloads/output_file (1).xlsx\")\n",
    "\n",
    "training_data.head(), testing_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7793160753791857, 0.7229707913753115)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "X_train = training_data.drop(columns='output')\n",
    "y_train = training_data['output']\n",
    "\n",
    "X_test = testing_data.drop(columns='output')\n",
    "y_test = testing_data['output']\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "r2, rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.37514484442789753, 1.216536324721879)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "X_train = training_data.drop(columns='output')\n",
    "y_train = training_data['output']\n",
    "\n",
    "X_test = testing_data.drop(columns='output')\n",
    "y_test = testing_data['output']\n",
    "\n",
    "model = SVR()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "r2, rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9700587682642764, 0.2662994280491751)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "X_train = training_data.drop(columns='output')\n",
    "y_train = training_data['output']\n",
    "\n",
    "X_test = testing_data.drop(columns='output')\n",
    "y_test = testing_data['output']\n",
    "\n",
    "model = XGBRegressor(subsample=0.6, reg_lambda= 0.1, reg_alpha= 0.01, n_estimators= 500, min_child_weight= 5, max_depth= 10, learning_rate= 0.01, gamma= 0.1, colsample_bytree= 1.0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2, rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.1493994\ttotal: 169ms\tremaining: 1m 24s\n",
      "1:\tlearn: 1.1350316\ttotal: 180ms\tremaining: 44.8s\n",
      "2:\tlearn: 1.1174223\ttotal: 189ms\tremaining: 31.4s\n",
      "3:\tlearn: 1.1004596\ttotal: 199ms\tremaining: 24.7s\n",
      "4:\tlearn: 1.0897464\ttotal: 209ms\tremaining: 20.7s\n",
      "5:\tlearn: 1.0746452\ttotal: 218ms\tremaining: 18s\n",
      "6:\tlearn: 1.0621315\ttotal: 227ms\tremaining: 16s\n",
      "7:\tlearn: 1.0496560\ttotal: 235ms\tremaining: 14.5s\n",
      "8:\tlearn: 1.0366932\ttotal: 244ms\tremaining: 13.3s\n",
      "9:\tlearn: 1.0246353\ttotal: 257ms\tremaining: 12.6s\n",
      "10:\tlearn: 1.0116028\ttotal: 266ms\tremaining: 11.8s\n",
      "11:\tlearn: 1.0030158\ttotal: 275ms\tremaining: 11.2s\n",
      "12:\tlearn: 0.9923163\ttotal: 285ms\tremaining: 10.7s\n",
      "13:\tlearn: 0.9813268\ttotal: 293ms\tremaining: 10.2s\n",
      "14:\tlearn: 0.9742824\ttotal: 301ms\tremaining: 9.74s\n",
      "15:\tlearn: 0.9624814\ttotal: 309ms\tremaining: 9.36s\n",
      "16:\tlearn: 0.9546358\ttotal: 318ms\tremaining: 9.02s\n",
      "17:\tlearn: 0.9454481\ttotal: 326ms\tremaining: 8.72s\n",
      "18:\tlearn: 0.9360255\ttotal: 334ms\tremaining: 8.46s\n",
      "19:\tlearn: 0.9247421\ttotal: 342ms\tremaining: 8.21s\n",
      "20:\tlearn: 0.9166750\ttotal: 350ms\tremaining: 7.99s\n",
      "21:\tlearn: 0.9099022\ttotal: 359ms\tremaining: 7.79s\n",
      "22:\tlearn: 0.9024078\ttotal: 367ms\tremaining: 7.62s\n",
      "23:\tlearn: 0.8924461\ttotal: 377ms\tremaining: 7.47s\n",
      "24:\tlearn: 0.8844401\ttotal: 390ms\tremaining: 7.41s\n",
      "25:\tlearn: 0.8807414\ttotal: 401ms\tremaining: 7.31s\n",
      "26:\tlearn: 0.8744903\ttotal: 412ms\tremaining: 7.22s\n",
      "27:\tlearn: 0.8658225\ttotal: 423ms\tremaining: 7.14s\n",
      "28:\tlearn: 0.8604901\ttotal: 433ms\tremaining: 7.03s\n",
      "29:\tlearn: 0.8538987\ttotal: 442ms\tremaining: 6.93s\n",
      "30:\tlearn: 0.8491194\ttotal: 452ms\tremaining: 6.83s\n",
      "31:\tlearn: 0.8417570\ttotal: 461ms\tremaining: 6.74s\n",
      "32:\tlearn: 0.8356030\ttotal: 469ms\tremaining: 6.64s\n",
      "33:\tlearn: 0.8292623\ttotal: 478ms\tremaining: 6.55s\n",
      "34:\tlearn: 0.8222286\ttotal: 486ms\tremaining: 6.46s\n",
      "35:\tlearn: 0.8165002\ttotal: 496ms\tremaining: 6.39s\n",
      "36:\tlearn: 0.8121461\ttotal: 504ms\tremaining: 6.31s\n",
      "37:\tlearn: 0.8087887\ttotal: 512ms\tremaining: 6.23s\n",
      "38:\tlearn: 0.8044645\ttotal: 520ms\tremaining: 6.15s\n",
      "39:\tlearn: 0.8004313\ttotal: 529ms\tremaining: 6.08s\n",
      "40:\tlearn: 0.7937506\ttotal: 537ms\tremaining: 6.01s\n",
      "41:\tlearn: 0.7893279\ttotal: 547ms\tremaining: 5.96s\n",
      "42:\tlearn: 0.7855489\ttotal: 555ms\tremaining: 5.9s\n",
      "43:\tlearn: 0.7814228\ttotal: 565ms\tremaining: 5.85s\n",
      "44:\tlearn: 0.7771514\ttotal: 574ms\tremaining: 5.8s\n",
      "45:\tlearn: 0.7734187\ttotal: 584ms\tremaining: 5.77s\n",
      "46:\tlearn: 0.7701076\ttotal: 598ms\tremaining: 5.77s\n",
      "47:\tlearn: 0.7674116\ttotal: 608ms\tremaining: 5.73s\n",
      "48:\tlearn: 0.7628523\ttotal: 617ms\tremaining: 5.67s\n",
      "49:\tlearn: 0.7590866\ttotal: 625ms\tremaining: 5.63s\n",
      "50:\tlearn: 0.7536158\ttotal: 633ms\tremaining: 5.58s\n",
      "51:\tlearn: 0.7478630\ttotal: 642ms\tremaining: 5.53s\n",
      "52:\tlearn: 0.7423055\ttotal: 650ms\tremaining: 5.48s\n",
      "53:\tlearn: 0.7378610\ttotal: 659ms\tremaining: 5.44s\n",
      "54:\tlearn: 0.7352646\ttotal: 667ms\tremaining: 5.39s\n",
      "55:\tlearn: 0.7319124\ttotal: 675ms\tremaining: 5.35s\n",
      "56:\tlearn: 0.7273951\ttotal: 684ms\tremaining: 5.31s\n",
      "57:\tlearn: 0.7230580\ttotal: 692ms\tremaining: 5.27s\n",
      "58:\tlearn: 0.7178718\ttotal: 702ms\tremaining: 5.24s\n",
      "59:\tlearn: 0.7116301\ttotal: 711ms\tremaining: 5.21s\n",
      "60:\tlearn: 0.7075543\ttotal: 720ms\tremaining: 5.18s\n",
      "61:\tlearn: 0.7030538\ttotal: 728ms\tremaining: 5.15s\n",
      "62:\tlearn: 0.6983216\ttotal: 737ms\tremaining: 5.11s\n",
      "63:\tlearn: 0.6936313\ttotal: 747ms\tremaining: 5.08s\n",
      "64:\tlearn: 0.6890220\ttotal: 756ms\tremaining: 5.06s\n",
      "65:\tlearn: 0.6851288\ttotal: 765ms\tremaining: 5.03s\n",
      "66:\tlearn: 0.6815571\ttotal: 780ms\tremaining: 5.04s\n",
      "67:\tlearn: 0.6762452\ttotal: 790ms\tremaining: 5.02s\n",
      "68:\tlearn: 0.6724174\ttotal: 800ms\tremaining: 5s\n",
      "69:\tlearn: 0.6693587\ttotal: 810ms\tremaining: 4.98s\n",
      "70:\tlearn: 0.6645440\ttotal: 820ms\tremaining: 4.95s\n",
      "71:\tlearn: 0.6604330\ttotal: 829ms\tremaining: 4.93s\n",
      "72:\tlearn: 0.6561795\ttotal: 838ms\tremaining: 4.9s\n",
      "73:\tlearn: 0.6531612\ttotal: 846ms\tremaining: 4.87s\n",
      "74:\tlearn: 0.6507095\ttotal: 855ms\tremaining: 4.84s\n",
      "75:\tlearn: 0.6474018\ttotal: 864ms\tremaining: 4.82s\n",
      "76:\tlearn: 0.6448286\ttotal: 873ms\tremaining: 4.79s\n",
      "77:\tlearn: 0.6427135\ttotal: 882ms\tremaining: 4.77s\n",
      "78:\tlearn: 0.6385600\ttotal: 892ms\tremaining: 4.75s\n",
      "79:\tlearn: 0.6340114\ttotal: 901ms\tremaining: 4.73s\n",
      "80:\tlearn: 0.6277924\ttotal: 911ms\tremaining: 4.71s\n",
      "81:\tlearn: 0.6237754\ttotal: 920ms\tremaining: 4.69s\n",
      "82:\tlearn: 0.6211668\ttotal: 928ms\tremaining: 4.66s\n",
      "83:\tlearn: 0.6173297\ttotal: 937ms\tremaining: 4.64s\n",
      "84:\tlearn: 0.6130958\ttotal: 957ms\tremaining: 4.67s\n",
      "85:\tlearn: 0.6104180\ttotal: 966ms\tremaining: 4.65s\n",
      "86:\tlearn: 0.6072780\ttotal: 975ms\tremaining: 4.63s\n",
      "87:\tlearn: 0.6036878\ttotal: 985ms\tremaining: 4.61s\n",
      "88:\tlearn: 0.6009633\ttotal: 997ms\tremaining: 4.61s\n",
      "89:\tlearn: 0.5976407\ttotal: 1.01s\tremaining: 4.59s\n",
      "90:\tlearn: 0.5938461\ttotal: 1.02s\tremaining: 4.57s\n",
      "91:\tlearn: 0.5900882\ttotal: 1.03s\tremaining: 4.55s\n",
      "92:\tlearn: 0.5844080\ttotal: 1.03s\tremaining: 4.53s\n",
      "93:\tlearn: 0.5818510\ttotal: 1.04s\tremaining: 4.51s\n",
      "94:\tlearn: 0.5779715\ttotal: 1.05s\tremaining: 4.49s\n",
      "95:\tlearn: 0.5742914\ttotal: 1.06s\tremaining: 4.47s\n",
      "96:\tlearn: 0.5695994\ttotal: 1.07s\tremaining: 4.45s\n",
      "97:\tlearn: 0.5669731\ttotal: 1.08s\tremaining: 4.43s\n",
      "98:\tlearn: 0.5649699\ttotal: 1.09s\tremaining: 4.41s\n",
      "99:\tlearn: 0.5612074\ttotal: 1.1s\tremaining: 4.39s\n",
      "100:\tlearn: 0.5576920\ttotal: 1.11s\tremaining: 4.37s\n",
      "101:\tlearn: 0.5548978\ttotal: 1.11s\tremaining: 4.35s\n",
      "102:\tlearn: 0.5512987\ttotal: 1.12s\tremaining: 4.33s\n",
      "103:\tlearn: 0.5467155\ttotal: 1.13s\tremaining: 4.31s\n",
      "104:\tlearn: 0.5446164\ttotal: 1.14s\tremaining: 4.29s\n",
      "105:\tlearn: 0.5397502\ttotal: 1.15s\tremaining: 4.27s\n",
      "106:\tlearn: 0.5366573\ttotal: 1.16s\tremaining: 4.25s\n",
      "107:\tlearn: 0.5326057\ttotal: 1.17s\tremaining: 4.24s\n",
      "108:\tlearn: 0.5287491\ttotal: 1.18s\tremaining: 4.22s\n",
      "109:\tlearn: 0.5245741\ttotal: 1.19s\tremaining: 4.21s\n",
      "110:\tlearn: 0.5205397\ttotal: 1.2s\tremaining: 4.21s\n",
      "111:\tlearn: 0.5168877\ttotal: 1.21s\tremaining: 4.19s\n",
      "112:\tlearn: 0.5138269\ttotal: 1.22s\tremaining: 4.18s\n",
      "113:\tlearn: 0.5119556\ttotal: 1.23s\tremaining: 4.16s\n",
      "114:\tlearn: 0.5075573\ttotal: 1.24s\tremaining: 4.15s\n",
      "115:\tlearn: 0.5047432\ttotal: 1.25s\tremaining: 4.13s\n",
      "116:\tlearn: 0.5023144\ttotal: 1.26s\tremaining: 4.11s\n",
      "117:\tlearn: 0.4991133\ttotal: 1.27s\tremaining: 4.1s\n",
      "118:\tlearn: 0.4953387\ttotal: 1.27s\tremaining: 4.08s\n",
      "119:\tlearn: 0.4939564\ttotal: 1.28s\tremaining: 4.07s\n",
      "120:\tlearn: 0.4920413\ttotal: 1.29s\tremaining: 4.05s\n",
      "121:\tlearn: 0.4905188\ttotal: 1.3s\tremaining: 4.04s\n",
      "122:\tlearn: 0.4886096\ttotal: 1.31s\tremaining: 4.02s\n",
      "123:\tlearn: 0.4857195\ttotal: 1.32s\tremaining: 4.01s\n",
      "124:\tlearn: 0.4824199\ttotal: 1.33s\tremaining: 4s\n",
      "125:\tlearn: 0.4806494\ttotal: 1.34s\tremaining: 3.98s\n",
      "126:\tlearn: 0.4775833\ttotal: 1.35s\tremaining: 3.97s\n",
      "127:\tlearn: 0.4740329\ttotal: 1.36s\tremaining: 3.95s\n",
      "128:\tlearn: 0.4709955\ttotal: 1.37s\tremaining: 3.94s\n",
      "129:\tlearn: 0.4690566\ttotal: 1.38s\tremaining: 3.93s\n",
      "130:\tlearn: 0.4659066\ttotal: 1.39s\tremaining: 3.92s\n",
      "131:\tlearn: 0.4637378\ttotal: 1.4s\tremaining: 3.91s\n",
      "132:\tlearn: 0.4609723\ttotal: 1.41s\tremaining: 3.9s\n",
      "133:\tlearn: 0.4575194\ttotal: 1.42s\tremaining: 3.89s\n",
      "134:\tlearn: 0.4549531\ttotal: 1.43s\tremaining: 3.87s\n",
      "135:\tlearn: 0.4520262\ttotal: 1.44s\tremaining: 3.86s\n",
      "136:\tlearn: 0.4497316\ttotal: 1.45s\tremaining: 3.85s\n",
      "137:\tlearn: 0.4476517\ttotal: 1.46s\tremaining: 3.83s\n",
      "138:\tlearn: 0.4444294\ttotal: 1.47s\tremaining: 3.82s\n",
      "139:\tlearn: 0.4422160\ttotal: 1.48s\tremaining: 3.81s\n",
      "140:\tlearn: 0.4397404\ttotal: 1.49s\tremaining: 3.79s\n",
      "141:\tlearn: 0.4366183\ttotal: 1.5s\tremaining: 3.78s\n",
      "142:\tlearn: 0.4339076\ttotal: 1.51s\tremaining: 3.76s\n",
      "143:\tlearn: 0.4297996\ttotal: 1.52s\tremaining: 3.76s\n",
      "144:\tlearn: 0.4283587\ttotal: 1.53s\tremaining: 3.74s\n",
      "145:\tlearn: 0.4265042\ttotal: 1.54s\tremaining: 3.73s\n",
      "146:\tlearn: 0.4231210\ttotal: 1.55s\tremaining: 3.72s\n",
      "147:\tlearn: 0.4212538\ttotal: 1.56s\tremaining: 3.71s\n",
      "148:\tlearn: 0.4191547\ttotal: 1.57s\tremaining: 3.69s\n",
      "149:\tlearn: 0.4163916\ttotal: 1.58s\tremaining: 3.68s\n",
      "150:\tlearn: 0.4146929\ttotal: 1.59s\tremaining: 3.67s\n",
      "151:\tlearn: 0.4120974\ttotal: 1.6s\tremaining: 3.66s\n",
      "152:\tlearn: 0.4098782\ttotal: 1.61s\tremaining: 3.65s\n",
      "153:\tlearn: 0.4069190\ttotal: 1.62s\tremaining: 3.64s\n",
      "154:\tlearn: 0.4043502\ttotal: 1.63s\tremaining: 3.63s\n",
      "155:\tlearn: 0.4015803\ttotal: 1.64s\tremaining: 3.62s\n",
      "156:\tlearn: 0.4001794\ttotal: 1.65s\tremaining: 3.6s\n",
      "157:\tlearn: 0.3984633\ttotal: 1.66s\tremaining: 3.59s\n",
      "158:\tlearn: 0.3966918\ttotal: 1.67s\tremaining: 3.58s\n",
      "159:\tlearn: 0.3948435\ttotal: 1.68s\tremaining: 3.56s\n",
      "160:\tlearn: 0.3920967\ttotal: 1.69s\tremaining: 3.55s\n",
      "161:\tlearn: 0.3900021\ttotal: 1.7s\tremaining: 3.54s\n",
      "162:\tlearn: 0.3880541\ttotal: 1.71s\tremaining: 3.53s\n",
      "163:\tlearn: 0.3857704\ttotal: 1.72s\tremaining: 3.52s\n",
      "164:\tlearn: 0.3840805\ttotal: 1.73s\tremaining: 3.5s\n",
      "165:\tlearn: 0.3814298\ttotal: 1.74s\tremaining: 3.49s\n",
      "166:\tlearn: 0.3790997\ttotal: 1.74s\tremaining: 3.48s\n",
      "167:\tlearn: 0.3768326\ttotal: 1.75s\tremaining: 3.47s\n",
      "168:\tlearn: 0.3749444\ttotal: 1.76s\tremaining: 3.46s\n",
      "169:\tlearn: 0.3726891\ttotal: 1.77s\tremaining: 3.44s\n",
      "170:\tlearn: 0.3707394\ttotal: 1.78s\tremaining: 3.43s\n",
      "171:\tlearn: 0.3693153\ttotal: 1.79s\tremaining: 3.42s\n",
      "172:\tlearn: 0.3681084\ttotal: 1.81s\tremaining: 3.42s\n",
      "173:\tlearn: 0.3664821\ttotal: 1.82s\tremaining: 3.4s\n",
      "174:\tlearn: 0.3648110\ttotal: 1.83s\tremaining: 3.39s\n",
      "175:\tlearn: 0.3633799\ttotal: 1.84s\tremaining: 3.38s\n",
      "176:\tlearn: 0.3618203\ttotal: 1.85s\tremaining: 3.37s\n",
      "177:\tlearn: 0.3596819\ttotal: 1.85s\tremaining: 3.36s\n",
      "178:\tlearn: 0.3576421\ttotal: 1.86s\tremaining: 3.35s\n",
      "179:\tlearn: 0.3555863\ttotal: 1.88s\tremaining: 3.33s\n",
      "180:\tlearn: 0.3529909\ttotal: 1.89s\tremaining: 3.32s\n",
      "181:\tlearn: 0.3509650\ttotal: 1.89s\tremaining: 3.31s\n",
      "182:\tlearn: 0.3490950\ttotal: 1.91s\tremaining: 3.32s\n",
      "183:\tlearn: 0.3475670\ttotal: 1.92s\tremaining: 3.31s\n",
      "184:\tlearn: 0.3461424\ttotal: 1.93s\tremaining: 3.29s\n",
      "185:\tlearn: 0.3446380\ttotal: 1.94s\tremaining: 3.28s\n",
      "186:\tlearn: 0.3434916\ttotal: 1.95s\tremaining: 3.27s\n",
      "187:\tlearn: 0.3418248\ttotal: 1.96s\tremaining: 3.26s\n",
      "188:\tlearn: 0.3401870\ttotal: 1.97s\tremaining: 3.24s\n",
      "189:\tlearn: 0.3386120\ttotal: 1.98s\tremaining: 3.23s\n",
      "190:\tlearn: 0.3373303\ttotal: 1.99s\tremaining: 3.22s\n",
      "191:\tlearn: 0.3361074\ttotal: 2s\tremaining: 3.21s\n",
      "192:\tlearn: 0.3348375\ttotal: 2.01s\tremaining: 3.2s\n",
      "193:\tlearn: 0.3331371\ttotal: 2.02s\tremaining: 3.19s\n",
      "194:\tlearn: 0.3315016\ttotal: 2.03s\tremaining: 3.18s\n",
      "195:\tlearn: 0.3302657\ttotal: 2.04s\tremaining: 3.17s\n",
      "196:\tlearn: 0.3289368\ttotal: 2.05s\tremaining: 3.15s\n",
      "197:\tlearn: 0.3271969\ttotal: 2.06s\tremaining: 3.14s\n",
      "198:\tlearn: 0.3259314\ttotal: 2.07s\tremaining: 3.13s\n",
      "199:\tlearn: 0.3240781\ttotal: 2.08s\tremaining: 3.12s\n",
      "200:\tlearn: 0.3221499\ttotal: 2.09s\tremaining: 3.1s\n",
      "201:\tlearn: 0.3208521\ttotal: 2.1s\tremaining: 3.09s\n",
      "202:\tlearn: 0.3184413\ttotal: 2.11s\tremaining: 3.08s\n",
      "203:\tlearn: 0.3174469\ttotal: 2.12s\tremaining: 3.07s\n",
      "204:\tlearn: 0.3160010\ttotal: 2.13s\tremaining: 3.06s\n",
      "205:\tlearn: 0.3147851\ttotal: 2.14s\tremaining: 3.05s\n",
      "206:\tlearn: 0.3131180\ttotal: 2.15s\tremaining: 3.04s\n",
      "207:\tlearn: 0.3114778\ttotal: 2.16s\tremaining: 3.03s\n",
      "208:\tlearn: 0.3101093\ttotal: 2.17s\tremaining: 3.02s\n",
      "209:\tlearn: 0.3084765\ttotal: 2.17s\tremaining: 3s\n",
      "210:\tlearn: 0.3078555\ttotal: 2.19s\tremaining: 2.99s\n",
      "211:\tlearn: 0.3062567\ttotal: 2.19s\tremaining: 2.98s\n",
      "212:\tlearn: 0.3049616\ttotal: 2.21s\tremaining: 2.97s\n",
      "213:\tlearn: 0.3037438\ttotal: 2.22s\tremaining: 2.96s\n",
      "214:\tlearn: 0.3025589\ttotal: 2.23s\tremaining: 2.95s\n",
      "215:\tlearn: 0.3008188\ttotal: 2.24s\tremaining: 2.94s\n",
      "216:\tlearn: 0.2995708\ttotal: 2.25s\tremaining: 2.93s\n",
      "217:\tlearn: 0.2978525\ttotal: 2.26s\tremaining: 2.92s\n",
      "218:\tlearn: 0.2963479\ttotal: 2.27s\tremaining: 2.91s\n",
      "219:\tlearn: 0.2951564\ttotal: 2.27s\tremaining: 2.9s\n",
      "220:\tlearn: 0.2938776\ttotal: 2.28s\tremaining: 2.88s\n",
      "221:\tlearn: 0.2923283\ttotal: 2.29s\tremaining: 2.87s\n",
      "222:\tlearn: 0.2919032\ttotal: 2.3s\tremaining: 2.86s\n",
      "223:\tlearn: 0.2903951\ttotal: 2.31s\tremaining: 2.85s\n",
      "224:\tlearn: 0.2885981\ttotal: 2.32s\tremaining: 2.84s\n",
      "225:\tlearn: 0.2873234\ttotal: 2.33s\tremaining: 2.83s\n",
      "226:\tlearn: 0.2859346\ttotal: 2.34s\tremaining: 2.82s\n",
      "227:\tlearn: 0.2853309\ttotal: 2.35s\tremaining: 2.81s\n",
      "228:\tlearn: 0.2844748\ttotal: 2.36s\tremaining: 2.79s\n",
      "229:\tlearn: 0.2828905\ttotal: 2.37s\tremaining: 2.78s\n",
      "230:\tlearn: 0.2813901\ttotal: 2.38s\tremaining: 2.77s\n",
      "231:\tlearn: 0.2800287\ttotal: 2.39s\tremaining: 2.76s\n",
      "232:\tlearn: 0.2786002\ttotal: 2.4s\tremaining: 2.75s\n",
      "233:\tlearn: 0.2775753\ttotal: 2.41s\tremaining: 2.74s\n",
      "234:\tlearn: 0.2759131\ttotal: 2.42s\tremaining: 2.73s\n",
      "235:\tlearn: 0.2748773\ttotal: 2.44s\tremaining: 2.72s\n",
      "236:\tlearn: 0.2733700\ttotal: 2.44s\tremaining: 2.71s\n",
      "237:\tlearn: 0.2724018\ttotal: 2.45s\tremaining: 2.7s\n",
      "238:\tlearn: 0.2717137\ttotal: 2.46s\tremaining: 2.69s\n",
      "239:\tlearn: 0.2702395\ttotal: 2.47s\tremaining: 2.68s\n",
      "240:\tlearn: 0.2692961\ttotal: 2.48s\tremaining: 2.67s\n",
      "241:\tlearn: 0.2686632\ttotal: 2.49s\tremaining: 2.66s\n",
      "242:\tlearn: 0.2676108\ttotal: 2.5s\tremaining: 2.64s\n",
      "243:\tlearn: 0.2663591\ttotal: 2.51s\tremaining: 2.63s\n",
      "244:\tlearn: 0.2650057\ttotal: 2.52s\tremaining: 2.62s\n",
      "245:\tlearn: 0.2641606\ttotal: 2.53s\tremaining: 2.61s\n",
      "246:\tlearn: 0.2634468\ttotal: 2.54s\tremaining: 2.6s\n",
      "247:\tlearn: 0.2622011\ttotal: 2.55s\tremaining: 2.59s\n",
      "248:\tlearn: 0.2614647\ttotal: 2.56s\tremaining: 2.58s\n",
      "249:\tlearn: 0.2608091\ttotal: 2.57s\tremaining: 2.57s\n",
      "250:\tlearn: 0.2598190\ttotal: 2.58s\tremaining: 2.56s\n",
      "251:\tlearn: 0.2584330\ttotal: 2.58s\tremaining: 2.54s\n",
      "252:\tlearn: 0.2578037\ttotal: 2.6s\tremaining: 2.53s\n",
      "253:\tlearn: 0.2568402\ttotal: 2.6s\tremaining: 2.52s\n",
      "254:\tlearn: 0.2557136\ttotal: 2.62s\tremaining: 2.51s\n",
      "255:\tlearn: 0.2546044\ttotal: 2.63s\tremaining: 2.5s\n",
      "256:\tlearn: 0.2540113\ttotal: 2.64s\tremaining: 2.49s\n",
      "257:\tlearn: 0.2530843\ttotal: 2.65s\tremaining: 2.48s\n",
      "258:\tlearn: 0.2519496\ttotal: 2.66s\tremaining: 2.47s\n",
      "259:\tlearn: 0.2512695\ttotal: 2.67s\tremaining: 2.46s\n",
      "260:\tlearn: 0.2507383\ttotal: 2.67s\tremaining: 2.45s\n",
      "261:\tlearn: 0.2499116\ttotal: 2.68s\tremaining: 2.44s\n",
      "262:\tlearn: 0.2491656\ttotal: 2.69s\tremaining: 2.43s\n",
      "263:\tlearn: 0.2480623\ttotal: 2.7s\tremaining: 2.42s\n",
      "264:\tlearn: 0.2468563\ttotal: 2.71s\tremaining: 2.4s\n",
      "265:\tlearn: 0.2460011\ttotal: 2.72s\tremaining: 2.39s\n",
      "266:\tlearn: 0.2448557\ttotal: 2.73s\tremaining: 2.38s\n",
      "267:\tlearn: 0.2443035\ttotal: 2.74s\tremaining: 2.37s\n",
      "268:\tlearn: 0.2439179\ttotal: 2.75s\tremaining: 2.36s\n",
      "269:\tlearn: 0.2429476\ttotal: 2.76s\tremaining: 2.35s\n",
      "270:\tlearn: 0.2416080\ttotal: 2.77s\tremaining: 2.34s\n",
      "271:\tlearn: 0.2403215\ttotal: 2.78s\tremaining: 2.33s\n",
      "272:\tlearn: 0.2392641\ttotal: 2.79s\tremaining: 2.32s\n",
      "273:\tlearn: 0.2380763\ttotal: 2.8s\tremaining: 2.31s\n",
      "274:\tlearn: 0.2375023\ttotal: 2.81s\tremaining: 2.3s\n",
      "275:\tlearn: 0.2367654\ttotal: 2.82s\tremaining: 2.29s\n",
      "276:\tlearn: 0.2359741\ttotal: 2.83s\tremaining: 2.28s\n",
      "277:\tlearn: 0.2354107\ttotal: 2.84s\tremaining: 2.27s\n",
      "278:\tlearn: 0.2344157\ttotal: 2.85s\tremaining: 2.26s\n",
      "279:\tlearn: 0.2336326\ttotal: 2.86s\tremaining: 2.25s\n",
      "280:\tlearn: 0.2328415\ttotal: 2.87s\tremaining: 2.24s\n",
      "281:\tlearn: 0.2320560\ttotal: 2.88s\tremaining: 2.23s\n",
      "282:\tlearn: 0.2316634\ttotal: 2.89s\tremaining: 2.21s\n",
      "283:\tlearn: 0.2309133\ttotal: 2.9s\tremaining: 2.2s\n",
      "284:\tlearn: 0.2300829\ttotal: 2.91s\tremaining: 2.19s\n",
      "285:\tlearn: 0.2293082\ttotal: 2.92s\tremaining: 2.18s\n",
      "286:\tlearn: 0.2287677\ttotal: 2.93s\tremaining: 2.17s\n",
      "287:\tlearn: 0.2276793\ttotal: 2.94s\tremaining: 2.16s\n",
      "288:\tlearn: 0.2272034\ttotal: 2.95s\tremaining: 2.15s\n",
      "289:\tlearn: 0.2265437\ttotal: 2.96s\tremaining: 2.14s\n",
      "290:\tlearn: 0.2259544\ttotal: 2.96s\tremaining: 2.13s\n",
      "291:\tlearn: 0.2250964\ttotal: 2.98s\tremaining: 2.12s\n",
      "292:\tlearn: 0.2243978\ttotal: 2.98s\tremaining: 2.11s\n",
      "293:\tlearn: 0.2234647\ttotal: 3s\tremaining: 2.1s\n",
      "294:\tlearn: 0.2226185\ttotal: 3s\tremaining: 2.09s\n",
      "295:\tlearn: 0.2218610\ttotal: 3.01s\tremaining: 2.08s\n",
      "296:\tlearn: 0.2211656\ttotal: 3.02s\tremaining: 2.07s\n",
      "297:\tlearn: 0.2204053\ttotal: 3.04s\tremaining: 2.06s\n",
      "298:\tlearn: 0.2195456\ttotal: 3.05s\tremaining: 2.05s\n",
      "299:\tlearn: 0.2190557\ttotal: 3.06s\tremaining: 2.04s\n",
      "300:\tlearn: 0.2185553\ttotal: 3.06s\tremaining: 2.03s\n",
      "301:\tlearn: 0.2177495\ttotal: 3.08s\tremaining: 2.02s\n",
      "302:\tlearn: 0.2171402\ttotal: 3.09s\tremaining: 2.01s\n",
      "303:\tlearn: 0.2166541\ttotal: 3.1s\tremaining: 2s\n",
      "304:\tlearn: 0.2161860\ttotal: 3.1s\tremaining: 1.99s\n",
      "305:\tlearn: 0.2152785\ttotal: 3.11s\tremaining: 1.97s\n",
      "306:\tlearn: 0.2147079\ttotal: 3.12s\tremaining: 1.96s\n",
      "307:\tlearn: 0.2143312\ttotal: 3.13s\tremaining: 1.95s\n",
      "308:\tlearn: 0.2138902\ttotal: 3.14s\tremaining: 1.94s\n",
      "309:\tlearn: 0.2134323\ttotal: 3.15s\tremaining: 1.93s\n",
      "310:\tlearn: 0.2127935\ttotal: 3.16s\tremaining: 1.92s\n",
      "311:\tlearn: 0.2122702\ttotal: 3.17s\tremaining: 1.91s\n",
      "312:\tlearn: 0.2119509\ttotal: 3.18s\tremaining: 1.9s\n",
      "313:\tlearn: 0.2114427\ttotal: 3.19s\tremaining: 1.89s\n",
      "314:\tlearn: 0.2107297\ttotal: 3.2s\tremaining: 1.88s\n",
      "315:\tlearn: 0.2100105\ttotal: 3.21s\tremaining: 1.87s\n",
      "316:\tlearn: 0.2095859\ttotal: 3.22s\tremaining: 1.86s\n",
      "317:\tlearn: 0.2087439\ttotal: 3.23s\tremaining: 1.85s\n",
      "318:\tlearn: 0.2084975\ttotal: 3.24s\tremaining: 1.84s\n",
      "319:\tlearn: 0.2082584\ttotal: 3.25s\tremaining: 1.83s\n",
      "320:\tlearn: 0.2076931\ttotal: 3.26s\tremaining: 1.82s\n",
      "321:\tlearn: 0.2069094\ttotal: 3.27s\tremaining: 1.81s\n",
      "322:\tlearn: 0.2062337\ttotal: 3.28s\tremaining: 1.8s\n",
      "323:\tlearn: 0.2055703\ttotal: 3.29s\tremaining: 1.79s\n",
      "324:\tlearn: 0.2050920\ttotal: 3.3s\tremaining: 1.78s\n",
      "325:\tlearn: 0.2045556\ttotal: 3.31s\tremaining: 1.76s\n",
      "326:\tlearn: 0.2039521\ttotal: 3.32s\tremaining: 1.76s\n",
      "327:\tlearn: 0.2034009\ttotal: 3.33s\tremaining: 1.75s\n",
      "328:\tlearn: 0.2027695\ttotal: 3.34s\tremaining: 1.74s\n",
      "329:\tlearn: 0.2019899\ttotal: 3.35s\tremaining: 1.73s\n",
      "330:\tlearn: 0.2013701\ttotal: 3.36s\tremaining: 1.72s\n",
      "331:\tlearn: 0.2006336\ttotal: 3.37s\tremaining: 1.71s\n",
      "332:\tlearn: 0.2002069\ttotal: 3.38s\tremaining: 1.7s\n",
      "333:\tlearn: 0.1996158\ttotal: 3.39s\tremaining: 1.68s\n",
      "334:\tlearn: 0.1990000\ttotal: 3.4s\tremaining: 1.67s\n",
      "335:\tlearn: 0.1984819\ttotal: 3.41s\tremaining: 1.66s\n",
      "336:\tlearn: 0.1979412\ttotal: 3.43s\tremaining: 1.66s\n",
      "337:\tlearn: 0.1976559\ttotal: 3.44s\tremaining: 1.65s\n",
      "338:\tlearn: 0.1970719\ttotal: 3.46s\tremaining: 1.64s\n",
      "339:\tlearn: 0.1965944\ttotal: 3.46s\tremaining: 1.63s\n",
      "340:\tlearn: 0.1960622\ttotal: 3.47s\tremaining: 1.62s\n",
      "341:\tlearn: 0.1956706\ttotal: 3.48s\tremaining: 1.61s\n",
      "342:\tlearn: 0.1952429\ttotal: 3.49s\tremaining: 1.6s\n",
      "343:\tlearn: 0.1947854\ttotal: 3.5s\tremaining: 1.59s\n",
      "344:\tlearn: 0.1944262\ttotal: 3.51s\tremaining: 1.58s\n",
      "345:\tlearn: 0.1942708\ttotal: 3.52s\tremaining: 1.57s\n",
      "346:\tlearn: 0.1938388\ttotal: 3.53s\tremaining: 1.56s\n",
      "347:\tlearn: 0.1931627\ttotal: 3.54s\tremaining: 1.55s\n",
      "348:\tlearn: 0.1925966\ttotal: 3.55s\tremaining: 1.54s\n",
      "349:\tlearn: 0.1920792\ttotal: 3.56s\tremaining: 1.53s\n",
      "350:\tlearn: 0.1917199\ttotal: 3.57s\tremaining: 1.51s\n",
      "351:\tlearn: 0.1912863\ttotal: 3.58s\tremaining: 1.5s\n",
      "352:\tlearn: 0.1906208\ttotal: 3.59s\tremaining: 1.49s\n",
      "353:\tlearn: 0.1902145\ttotal: 3.6s\tremaining: 1.48s\n",
      "354:\tlearn: 0.1898324\ttotal: 3.61s\tremaining: 1.47s\n",
      "355:\tlearn: 0.1893071\ttotal: 3.62s\tremaining: 1.46s\n",
      "356:\tlearn: 0.1888492\ttotal: 3.63s\tremaining: 1.45s\n",
      "357:\tlearn: 0.1883424\ttotal: 3.63s\tremaining: 1.44s\n",
      "358:\tlearn: 0.1878668\ttotal: 3.65s\tremaining: 1.43s\n",
      "359:\tlearn: 0.1873224\ttotal: 3.66s\tremaining: 1.42s\n",
      "360:\tlearn: 0.1867923\ttotal: 3.67s\tremaining: 1.41s\n",
      "361:\tlearn: 0.1864975\ttotal: 3.68s\tremaining: 1.4s\n",
      "362:\tlearn: 0.1860158\ttotal: 3.69s\tremaining: 1.39s\n",
      "363:\tlearn: 0.1857450\ttotal: 3.7s\tremaining: 1.38s\n",
      "364:\tlearn: 0.1852609\ttotal: 3.71s\tremaining: 1.37s\n",
      "365:\tlearn: 0.1847837\ttotal: 3.72s\tremaining: 1.36s\n",
      "366:\tlearn: 0.1845077\ttotal: 3.73s\tremaining: 1.35s\n",
      "367:\tlearn: 0.1839223\ttotal: 3.74s\tremaining: 1.34s\n",
      "368:\tlearn: 0.1835123\ttotal: 3.75s\tremaining: 1.33s\n",
      "369:\tlearn: 0.1830334\ttotal: 3.76s\tremaining: 1.32s\n",
      "370:\tlearn: 0.1827102\ttotal: 3.77s\tremaining: 1.31s\n",
      "371:\tlearn: 0.1825680\ttotal: 3.77s\tremaining: 1.3s\n",
      "372:\tlearn: 0.1822320\ttotal: 3.78s\tremaining: 1.29s\n",
      "373:\tlearn: 0.1818541\ttotal: 3.79s\tremaining: 1.28s\n",
      "374:\tlearn: 0.1812925\ttotal: 3.8s\tremaining: 1.27s\n",
      "375:\tlearn: 0.1809640\ttotal: 3.81s\tremaining: 1.26s\n",
      "376:\tlearn: 0.1805049\ttotal: 3.82s\tremaining: 1.25s\n",
      "377:\tlearn: 0.1800918\ttotal: 3.83s\tremaining: 1.24s\n",
      "378:\tlearn: 0.1797924\ttotal: 3.84s\tremaining: 1.23s\n",
      "379:\tlearn: 0.1795848\ttotal: 3.85s\tremaining: 1.22s\n",
      "380:\tlearn: 0.1794756\ttotal: 3.86s\tremaining: 1.21s\n",
      "381:\tlearn: 0.1790924\ttotal: 3.88s\tremaining: 1.2s\n",
      "382:\tlearn: 0.1786349\ttotal: 3.89s\tremaining: 1.19s\n",
      "383:\tlearn: 0.1781065\ttotal: 3.9s\tremaining: 1.18s\n",
      "384:\tlearn: 0.1779066\ttotal: 3.9s\tremaining: 1.17s\n",
      "385:\tlearn: 0.1776753\ttotal: 3.92s\tremaining: 1.16s\n",
      "386:\tlearn: 0.1773032\ttotal: 3.92s\tremaining: 1.15s\n",
      "387:\tlearn: 0.1769765\ttotal: 3.93s\tremaining: 1.14s\n",
      "388:\tlearn: 0.1766412\ttotal: 3.94s\tremaining: 1.13s\n",
      "389:\tlearn: 0.1764196\ttotal: 3.95s\tremaining: 1.11s\n",
      "390:\tlearn: 0.1761071\ttotal: 3.96s\tremaining: 1.1s\n",
      "391:\tlearn: 0.1757040\ttotal: 3.97s\tremaining: 1.09s\n",
      "392:\tlearn: 0.1753774\ttotal: 3.98s\tremaining: 1.08s\n",
      "393:\tlearn: 0.1749992\ttotal: 3.99s\tremaining: 1.07s\n",
      "394:\tlearn: 0.1744498\ttotal: 4s\tremaining: 1.06s\n",
      "395:\tlearn: 0.1740643\ttotal: 4.01s\tremaining: 1.05s\n",
      "396:\tlearn: 0.1737989\ttotal: 4.02s\tremaining: 1.04s\n",
      "397:\tlearn: 0.1735428\ttotal: 4.03s\tremaining: 1.03s\n",
      "398:\tlearn: 0.1731852\ttotal: 4.04s\tremaining: 1.02s\n",
      "399:\tlearn: 0.1729210\ttotal: 4.05s\tremaining: 1.01s\n",
      "400:\tlearn: 0.1726641\ttotal: 4.06s\tremaining: 1s\n",
      "401:\tlearn: 0.1723093\ttotal: 4.07s\tremaining: 992ms\n",
      "402:\tlearn: 0.1719992\ttotal: 4.08s\tremaining: 982ms\n",
      "403:\tlearn: 0.1717519\ttotal: 4.09s\tremaining: 972ms\n",
      "404:\tlearn: 0.1713675\ttotal: 4.1s\tremaining: 962ms\n",
      "405:\tlearn: 0.1708724\ttotal: 4.11s\tremaining: 952ms\n",
      "406:\tlearn: 0.1704610\ttotal: 4.12s\tremaining: 942ms\n",
      "407:\tlearn: 0.1701964\ttotal: 4.13s\tremaining: 931ms\n",
      "408:\tlearn: 0.1697497\ttotal: 4.14s\tremaining: 921ms\n",
      "409:\tlearn: 0.1695146\ttotal: 4.15s\tremaining: 911ms\n",
      "410:\tlearn: 0.1692097\ttotal: 4.16s\tremaining: 901ms\n",
      "411:\tlearn: 0.1689385\ttotal: 4.17s\tremaining: 890ms\n",
      "412:\tlearn: 0.1687463\ttotal: 4.18s\tremaining: 880ms\n",
      "413:\tlearn: 0.1684664\ttotal: 4.19s\tremaining: 870ms\n",
      "414:\tlearn: 0.1681488\ttotal: 4.2s\tremaining: 860ms\n",
      "415:\tlearn: 0.1677740\ttotal: 4.21s\tremaining: 849ms\n",
      "416:\tlearn: 0.1675469\ttotal: 4.21s\tremaining: 839ms\n",
      "417:\tlearn: 0.1672198\ttotal: 4.22s\tremaining: 829ms\n",
      "418:\tlearn: 0.1669796\ttotal: 4.23s\tremaining: 819ms\n",
      "419:\tlearn: 0.1666986\ttotal: 4.24s\tremaining: 808ms\n",
      "420:\tlearn: 0.1665071\ttotal: 4.25s\tremaining: 798ms\n",
      "421:\tlearn: 0.1661912\ttotal: 4.26s\tremaining: 788ms\n",
      "422:\tlearn: 0.1659163\ttotal: 4.28s\tremaining: 779ms\n",
      "423:\tlearn: 0.1656911\ttotal: 4.29s\tremaining: 768ms\n",
      "424:\tlearn: 0.1654727\ttotal: 4.3s\tremaining: 758ms\n",
      "425:\tlearn: 0.1651478\ttotal: 4.31s\tremaining: 748ms\n",
      "426:\tlearn: 0.1648055\ttotal: 4.32s\tremaining: 738ms\n",
      "427:\tlearn: 0.1646082\ttotal: 4.33s\tremaining: 728ms\n",
      "428:\tlearn: 0.1644046\ttotal: 4.33s\tremaining: 717ms\n",
      "429:\tlearn: 0.1640668\ttotal: 4.34s\tremaining: 707ms\n",
      "430:\tlearn: 0.1637913\ttotal: 4.35s\tremaining: 697ms\n",
      "431:\tlearn: 0.1634457\ttotal: 4.36s\tremaining: 687ms\n",
      "432:\tlearn: 0.1632617\ttotal: 4.37s\tremaining: 677ms\n",
      "433:\tlearn: 0.1631885\ttotal: 4.38s\tremaining: 667ms\n",
      "434:\tlearn: 0.1629278\ttotal: 4.39s\tremaining: 656ms\n",
      "435:\tlearn: 0.1627316\ttotal: 4.4s\tremaining: 646ms\n",
      "436:\tlearn: 0.1623997\ttotal: 4.41s\tremaining: 636ms\n",
      "437:\tlearn: 0.1622273\ttotal: 4.42s\tremaining: 626ms\n",
      "438:\tlearn: 0.1617788\ttotal: 4.43s\tremaining: 616ms\n",
      "439:\tlearn: 0.1616051\ttotal: 4.44s\tremaining: 605ms\n",
      "440:\tlearn: 0.1613242\ttotal: 4.45s\tremaining: 595ms\n",
      "441:\tlearn: 0.1612134\ttotal: 4.46s\tremaining: 585ms\n",
      "442:\tlearn: 0.1609120\ttotal: 4.47s\tremaining: 575ms\n",
      "443:\tlearn: 0.1605690\ttotal: 4.48s\tremaining: 565ms\n",
      "444:\tlearn: 0.1603103\ttotal: 4.49s\tremaining: 555ms\n",
      "445:\tlearn: 0.1601883\ttotal: 4.5s\tremaining: 545ms\n",
      "446:\tlearn: 0.1599010\ttotal: 4.51s\tremaining: 535ms\n",
      "447:\tlearn: 0.1598063\ttotal: 4.52s\tremaining: 525ms\n",
      "448:\tlearn: 0.1595355\ttotal: 4.53s\tremaining: 515ms\n",
      "449:\tlearn: 0.1592760\ttotal: 4.54s\tremaining: 504ms\n",
      "450:\tlearn: 0.1591217\ttotal: 4.55s\tremaining: 494ms\n",
      "451:\tlearn: 0.1588787\ttotal: 4.56s\tremaining: 484ms\n",
      "452:\tlearn: 0.1586938\ttotal: 4.57s\tremaining: 474ms\n",
      "453:\tlearn: 0.1584912\ttotal: 4.58s\tremaining: 464ms\n",
      "454:\tlearn: 0.1580808\ttotal: 4.59s\tremaining: 454ms\n",
      "455:\tlearn: 0.1578756\ttotal: 4.59s\tremaining: 443ms\n",
      "456:\tlearn: 0.1576257\ttotal: 4.6s\tremaining: 433ms\n",
      "457:\tlearn: 0.1574436\ttotal: 4.61s\tremaining: 423ms\n",
      "458:\tlearn: 0.1572985\ttotal: 4.62s\tremaining: 413ms\n",
      "459:\tlearn: 0.1570505\ttotal: 4.63s\tremaining: 403ms\n",
      "460:\tlearn: 0.1569077\ttotal: 4.64s\tremaining: 393ms\n",
      "461:\tlearn: 0.1566160\ttotal: 4.65s\tremaining: 383ms\n",
      "462:\tlearn: 0.1562780\ttotal: 4.67s\tremaining: 373ms\n",
      "463:\tlearn: 0.1560840\ttotal: 4.68s\tremaining: 363ms\n",
      "464:\tlearn: 0.1559682\ttotal: 4.69s\tremaining: 353ms\n",
      "465:\tlearn: 0.1556460\ttotal: 4.7s\tremaining: 343ms\n",
      "466:\tlearn: 0.1554536\ttotal: 4.71s\tremaining: 333ms\n",
      "467:\tlearn: 0.1552168\ttotal: 4.72s\tremaining: 323ms\n",
      "468:\tlearn: 0.1549918\ttotal: 4.73s\tremaining: 313ms\n",
      "469:\tlearn: 0.1547539\ttotal: 4.74s\tremaining: 303ms\n",
      "470:\tlearn: 0.1544533\ttotal: 4.75s\tremaining: 293ms\n",
      "471:\tlearn: 0.1542217\ttotal: 4.76s\tremaining: 282ms\n",
      "472:\tlearn: 0.1539970\ttotal: 4.77s\tremaining: 272ms\n",
      "473:\tlearn: 0.1537293\ttotal: 4.78s\tremaining: 262ms\n",
      "474:\tlearn: 0.1534773\ttotal: 4.79s\tremaining: 252ms\n",
      "475:\tlearn: 0.1532773\ttotal: 4.8s\tremaining: 242ms\n",
      "476:\tlearn: 0.1531190\ttotal: 4.81s\tremaining: 232ms\n",
      "477:\tlearn: 0.1530135\ttotal: 4.82s\tremaining: 222ms\n",
      "478:\tlearn: 0.1528820\ttotal: 4.83s\tremaining: 212ms\n",
      "479:\tlearn: 0.1528081\ttotal: 4.84s\tremaining: 202ms\n",
      "480:\tlearn: 0.1525836\ttotal: 4.85s\tremaining: 191ms\n",
      "481:\tlearn: 0.1523918\ttotal: 4.86s\tremaining: 181ms\n",
      "482:\tlearn: 0.1521875\ttotal: 4.86s\tremaining: 171ms\n",
      "483:\tlearn: 0.1520431\ttotal: 4.87s\tremaining: 161ms\n",
      "484:\tlearn: 0.1518545\ttotal: 4.88s\tremaining: 151ms\n",
      "485:\tlearn: 0.1515717\ttotal: 4.9s\tremaining: 141ms\n",
      "486:\tlearn: 0.1514276\ttotal: 4.91s\tremaining: 131ms\n",
      "487:\tlearn: 0.1512036\ttotal: 4.92s\tremaining: 121ms\n",
      "488:\tlearn: 0.1511041\ttotal: 4.93s\tremaining: 111ms\n",
      "489:\tlearn: 0.1509402\ttotal: 4.94s\tremaining: 101ms\n",
      "490:\tlearn: 0.1507294\ttotal: 4.95s\tremaining: 90.7ms\n",
      "491:\tlearn: 0.1505147\ttotal: 4.96s\tremaining: 80.6ms\n",
      "492:\tlearn: 0.1502950\ttotal: 4.96s\tremaining: 70.5ms\n",
      "493:\tlearn: 0.1501861\ttotal: 4.97s\tremaining: 60.4ms\n",
      "494:\tlearn: 0.1499936\ttotal: 4.98s\tremaining: 50.3ms\n",
      "495:\tlearn: 0.1498508\ttotal: 4.99s\tremaining: 40.3ms\n",
      "496:\tlearn: 0.1497690\ttotal: 5s\tremaining: 30.2ms\n",
      "497:\tlearn: 0.1496775\ttotal: 5.01s\tremaining: 20.1ms\n",
      "498:\tlearn: 0.1495939\ttotal: 5.02s\tremaining: 10.1ms\n",
      "499:\tlearn: 0.1494152\ttotal: 5.03s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9700587682642764, 0.22703778853666443)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "X_train = training_data.drop(columns='output')\n",
    "y_train = training_data['output']\n",
    "\n",
    "X_test = testing_data.drop(columns='output')\n",
    "y_test = testing_data['output']\n",
    "\n",
    "model=CatBoostRegressor(learning_rate=0.1, l2_leaf_reg= 7, iterations= 500, depth=6, border_count= 50)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2, rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9033148681880436, 0.47853669873108023)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "X_train = training_data.drop(columns='output')\n",
    "y_train = training_data['output']\n",
    "\n",
    "X_test = testing_data.drop(columns='output')\n",
    "y_test = testing_data['output']\n",
    "\n",
    "\n",
    "model=RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2, rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6751767336122496, 0.8771199053916505)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "\n",
    "model=AdaBoostRegressor(n_estimators= 300, loss='square', learning_rate=0.5)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2, rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9814175842908336, 0.2097908237022824)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "\n",
    "model = KNeighborsRegressor(metric='minkowski', n_neighbors=6, weights='distance')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aryan\\radioconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6697425026908941, 0.8844264965401825)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "model = MLPRegressor(solver= 'adam', learning_rate='constant', alpha=0.0001, activation='relu')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.21532769109156769, 1.3632627423239139)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "model = DecisionTreeRegressor(max_depth=1000, max_features=200, min_samples_leaf=100,\n",
    "                      min_samples_split=50, random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
