{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\V R N S Nikhil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "33 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "13 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\V R N S Nikhil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\V R N S Nikhil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\V R N S Nikhil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 171, in fit\n",
      "    sample_weight, estimator_weight, estimator_error = self._boost(\n",
      "                                                       ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\V R N S Nikhil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 1168, in _boost\n",
      "    estimator.fit(X_, y_)\n",
      "  File \"c:\\Users\\V R N S Nikhil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\V R N S Nikhil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\V R N S Nikhil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of DecisionTreeRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\V R N S Nikhil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\V R N S Nikhil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\V R N S Nikhil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 171, in fit\n",
      "    sample_weight, estimator_weight, estimator_error = self._boost(\n",
      "                                                       ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\V R N S Nikhil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 1168, in _boost\n",
      "    estimator.fit(X_, y_)\n",
      "  File \"c:\\Users\\V R N S Nikhil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\V R N S Nikhil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\V R N S Nikhil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of DecisionTreeRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\V R N S Nikhil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [ 0.08649698  0.11937456         nan -0.05277245  0.06266114 -0.03872206\n",
      "  0.01571416  0.01416976         nan  0.12785524  0.0050175   0.01421822\n",
      " -0.017398    0.09176852  0.06824026         nan  0.10576292  0.00800873\n",
      "         nan         nan  0.02981281 -0.08580385         nan  0.09770571\n",
      "  0.0284896   0.11023977 -0.06175495  0.01965163  0.01285144  0.07339878\n",
      " -0.02184823 -0.07822911         nan         nan         nan  0.00479314\n",
      " -0.07318896 -0.0670977   0.10313038         nan -0.0200848  -0.00272908\n",
      "  0.00186479         nan -0.01811052 -0.04775874  0.09920833 -0.0386387\n",
      " -0.11307782  0.01568643]\n",
      "  warnings.warn(\n",
      "c:\\Users\\V R N S Nikhil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for AdaBoost Regressor: {'n_estimators': 400, 'loss': 'exponential', 'learning_rate': 1.0, 'base_estimator__min_samples_split': 5, 'base_estimator__min_samples_leaf': 2, 'base_estimator__max_features': None, 'base_estimator__max_depth': 10}\n",
      "Best Cross-Validation Score for AdaBoost Regressor: 0.1278552380961158\n",
      "R2 Score on Test Set for AdaBoost Regressor: 0.2877110089748449\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV,GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Load the data\n",
    "file_path = 'C:\\\\Users\\\\V R N S Nikhil\\\\OneDrive\\\\Desktop\\\\4th_sem\\\\ML\\\\FINAL\\\\ML\\\\Auto.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('output', axis=1)\n",
    "y = data['output']\n",
    "\n",
    "data['output'].value_counts()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize the feature values\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the extended parameter grid for AdaBoost Regressor\n",
    "param_grid_adaboost = {\n",
    "    'n_estimators': [50, 100, 200, 300, 400, 500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.5, 1.0],\n",
    "    'loss': ['linear', 'square', 'exponential'],\n",
    "    'base_estimator__max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'base_estimator__min_samples_split': [2, 5, 10],\n",
    "    'base_estimator__min_samples_leaf': [1, 2, 4],\n",
    "    'base_estimator__max_features': [None, 'auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Initialize the base estimator\n",
    "base_estimator = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Initialize the AdaBoost Regressor\n",
    "adaboost_regressor = AdaBoostRegressor(base_estimator=base_estimator, random_state=42)\n",
    "\n",
    "# Set up the randomized search with cross-validation for AdaBoost Regressor\n",
    "random_search_adaboost = RandomizedSearchCV(estimator=adaboost_regressor, param_distributions=param_grid_adaboost, n_iter=50, cv=3, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the randomized search model for AdaBoost Regressor\n",
    "random_search_adaboost.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters and the best score for AdaBoost Regressor\n",
    "best_params_adaboost = random_search_adaboost.best_params_\n",
    "best_score_adaboost = random_search_adaboost.best_score_\n",
    "\n",
    "print(\"Best Parameters for AdaBoost Regressor:\", best_params_adaboost)\n",
    "print(\"Best Cross-Validation Score for AdaBoost Regressor:\", best_score_adaboost)\n",
    "\n",
    "# Evaluate the AdaBoost Regressor on the test set\n",
    "y_pred_adaboost = random_search_adaboost.predict(X_test_scaled)\n",
    "r2_adaboost = r2_score(y_test, y_pred_adaboost)\n",
    "print(\"R2 Score on Test Set for AdaBoost Regressor:\", r2_adaboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'solver': 'adam', 'learning_rate': 'constant', 'hidden_layer_sizes': (100, 100), 'alpha': 0.0001, 'activation': 'relu'}\n",
      "Best Cross-Validation Score: 0.19958920805136682\n",
      "R2 Score on Test Set: 0.4044178348407108\n",
      "RMSE on Test Set: 0.9054122458655068\n",
      "Cross-Validation RMSE Mean: 1.0441390233139205\n",
      "Cross-Validation RMSE Std Dev: 0.022947655244567\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "file_path = 'C:\\\\Users\\\\V R N S Nikhil\\\\OneDrive\\\\Desktop\\\\4th_sem\\\\ML\\\\FINAL\\\\ML\\\\MathBert.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('output', axis=1)\n",
    "y = data['output']\n",
    "\n",
    "# Custom round function\n",
    "def custom_round(value):\n",
    "    integer_part = int(value)\n",
    "    decimal_part = value - integer_part\n",
    "    if decimal_part == 0.5:\n",
    "        return value\n",
    "    else:\n",
    "        return round(value)\n",
    "\n",
    "data['output'] = data['output'].apply(custom_round)\n",
    "data['output'].value_counts()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize the feature values\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50), (100, 100)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'learning_rate': ['constant', 'adaptive'],\n",
    "}\n",
    "\n",
    "# Initialize the MLP regressor\n",
    "mlp_regressor = MLPRegressor(max_iter=300, random_state=42)\n",
    "\n",
    "# Set up the randomized search with cross-validation\n",
    "random_search = RandomizedSearchCV(estimator=mlp_regressor, param_distributions=param_grid, n_iter=20, cv=3, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the randomized search model\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters and the best score\n",
    "best_params = random_search.best_params_\n",
    "best_score = random_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Cross-Validation Score:\", best_score)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred = random_search.predict(X_test_scaled)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Perform cross-validation to get the mean and std of RMSE\n",
    "neg_mse_scores = cross_val_score(random_search.best_estimator_, X_train_scaled, y_train, scoring='neg_mean_squared_error', cv=3)\n",
    "rmse_scores = np.sqrt(-neg_mse_scores)\n",
    "\n",
    "rmse_mean = rmse_scores.mean()\n",
    "rmse_std = rmse_scores.std()\n",
    "\n",
    "print(\"R2 Score on Test Set:\", r2)\n",
    "print(\"RMSE on Test Set:\", rmse)\n",
    "print(\"Cross-Validation RMSE Mean:\", rmse_mean)\n",
    "print(\"Cross-Validation RMSE Std Dev:\", rmse_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'splitter': 'best', 'min_samples_split': 2, 'min_samples_leaf': 10, 'min_impurity_decrease': 0.05, 'max_leaf_nodes': 80, 'max_features': 'log2', 'max_depth': None, 'criterion': 'squared_error'}\n",
      "Best Cross-Validation Score: -0.005874197339122163\n",
      "R2 Score on Test Set: -0.0071507654622853245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\V R N S Nikhil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "42 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "21 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\V R N S Nikhil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\V R N S Nikhil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\V R N S Nikhil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\V R N S Nikhil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of DecisionTreeRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "21 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\V R N S Nikhil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\V R N S Nikhil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\V R N S Nikhil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\V R N S Nikhil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of DecisionTreeRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\V R N S Nikhil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [        nan -0.02231181         nan -0.0058742  -0.0058742  -0.24148901\n",
      " -0.02231181         nan -0.0058742  -0.3291824  -0.25494486 -0.30456209\n",
      " -0.16279074 -0.0058742  -0.0058742          nan -0.04595011 -0.42329002\n",
      "         nan -0.04547796 -0.40419102 -0.0058742          nan -0.06325564\n",
      " -0.26884896         nan -0.09949454 -0.24148901 -0.23686015 -0.06325564\n",
      " -0.0058742          nan -0.0058742          nan -0.0058742          nan\n",
      " -0.0058742  -0.14258967         nan -0.03837137         nan -0.14444486\n",
      "         nan -0.12751063 -0.07159789 -0.0058742  -0.02231181 -0.11287866\n",
      " -0.02231181         nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Load the data\n",
    "file_path = 'C:\\\\Users\\\\V R N S Nikhil\\\\OneDrive\\\\Desktop\\\\4th_sem\\\\ML\\\\FINAL\\\\ML\\\\Auto.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('output', axis=1)\n",
    "y = data['output']\n",
    "\n",
    "def custom_round(value):\n",
    "    integer_part = int(value)\n",
    "    decimal_part = value - integer_part\n",
    "    if decimal_part == 0.5:\n",
    "        return value\n",
    "    else:\n",
    "        return round(value)\n",
    "\n",
    "data['output'] = data['output'].apply(custom_round)\n",
    "data['output'].value_counts()\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize the feature values\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the extended parameter grid\n",
    "param_grid = {\n",
    "    'criterion': ['squared_error'],\n",
    "    'splitter': ['best'],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "    'min_samples_split': [2, 5, 10, 15, 20],\n",
    "    'min_samples_leaf': [1, 2, 4, 6, 8, 10],\n",
    "    'max_features': [None, 'auto', 'sqrt', 'log2'],\n",
    "    'max_leaf_nodes': [None, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "    'min_impurity_decrease': [0.0, 0.01, 0.02, 0.05, 0.1]\n",
    "}\n",
    "\n",
    "# Initialize the Decision Tree Regressor\n",
    "dt_regressor = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Set up the randomized search with cross-validation\n",
    "random_search = RandomizedSearchCV(estimator=dt_regressor, param_distributions=param_grid, n_iter=50, cv=3, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the randomized search model\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters and the best score\n",
    "best_params = random_search.best_params_\n",
    "best_score = random_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Cross-Validation Score:\", best_score)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred = random_search.predict(X_test_scaled)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R2 Score on Test Set:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R^2 score: 0.8057284435398251\n",
      "Testing R^2 score: -0.28406784523837536\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'C:\\\\Users\\\\V R N S Nikhil\\\\OneDrive\\\\Desktop\\\\4th_sem\\\\ML\\\\FINAL\\\\ML\\\\Auto.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop('output', axis=1)\n",
    "y = data['output']\n",
    "def custom_round(value):\n",
    "    integer_part = int(value)\n",
    "    decimal_part = value - integer_part\n",
    "    if decimal_part == 0.5:\n",
    "        return value\n",
    "    else:\n",
    "        return round(value)\n",
    "\n",
    "data['output'] = data['output'].apply(custom_round)\n",
    "data['output'].value_counts()\n",
    "\n",
    "# Handle missing values in the features and target\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "y_imputed = SimpleImputer(strategy='mean').fit_transform(y.values.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Apply PCA to reduce dimensionality\n",
    "pca = PCA(n_components=0.95)\n",
    "scaler = StandardScaler()\n",
    "X_reduced = scaler.fit_transform(pca.fit_transform(X_imputed))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y_imputed, test_size=0.2, random_state=42)\n",
    "\n",
    "# Set up the Random Forest Regressor\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = rf_regressor.predict(X_train)\n",
    "y_pred_test = rf_regressor.predict(X_test)\n",
    "\n",
    "# Calculate the R^2 score\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Training R^2 score:\", r2_train)\n",
    "print(\"Testing R^2 score:\", r2_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for XGBoost Regressor: {'subsample': 0.6, 'reg_lambda': 0, 'reg_alpha': 0, 'n_estimators': 200, 'min_child_weight': 3, 'max_depth': 5, 'learning_rate': 0.05, 'gamma': 0.3, 'colsample_bytree': 1.0}\n",
      "Best Cross-Validation Score for XGBoost Regressor: 0.12655874256629293\n",
      "R2 Score on Test Set for XGBoost Regressor: 0.2915193329406416\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Load the data\n",
    "file_path = 'C:\\\\Users\\\\V R N S Nikhil\\\\OneDrive\\\\Desktop\\\\4th_sem\\\\ML\\\\FINAL\\\\ML\\\\Auto.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('output', axis=1)\n",
    "y = data['output']\n",
    "def custom_round(value):\n",
    "    integer_part = int(value)\n",
    "    decimal_part = value - integer_part\n",
    "    if decimal_part == 0.5:\n",
    "        return value\n",
    "    else:\n",
    "        return round(value)\n",
    "\n",
    "data['output'] = data['output'].apply(custom_round)\n",
    "data['output'].value_counts()\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize the feature values\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the extended parameter grid for XGBoost Regressor\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3],\n",
    "    'reg_alpha': [0, 0.01, 0.1, 1],\n",
    "    'reg_lambda': [0, 0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost Regressor\n",
    "xgb_regressor = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "# Set up the randomized search with cross-validation for XGBoost Regressor\n",
    "random_search_xgb = RandomizedSearchCV(estimator=xgb_regressor, param_distributions=param_grid_xgb, n_iter=50, cv=3, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the randomized search model for XGBoost Regressor\n",
    "random_search_xgb.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters and the best score for XGBoost Regressor\n",
    "best_params_xgb = random_search_xgb.best_params_\n",
    "best_score_xgb = random_search_xgb.best_score_\n",
    "\n",
    "print(\"Best Parameters for XGBoost Regressor:\", best_params_xgb)\n",
    "print(\"Best Cross-Validation Score for XGBoost Regressor:\", best_score_xgb)\n",
    "\n",
    "# Evaluate the XGBoost Regressor on the test set\n",
    "y_pred_xgb = random_search_xgb.predict(X_test_scaled)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "print(\"R2 Score on Test Set for XGBoost Regressor:\", r2_xgb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
